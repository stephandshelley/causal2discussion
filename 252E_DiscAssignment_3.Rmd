---
title: 'Discussion Assignment #3'
author: "Sabrina Boyce, Shelley Facente, and Steph Holm"
date: "11/6/2019"
output: beamer_presentation
---

<!--
# Question 1: Specify the question of interest. How does this question differ from that addressed in the original analysis of the randomized trial? What was the authors' motivation for doing a secondary analysis?
The question of interest is: *What causal effect does breastfeeding duration have on the number of infections a newborn is expected to experience in their first year?* This differs from the original analysis in the RCT because they were originally evaluating the effect of longer breastfeeding duration (via the PROBIT intervention) on gastrointestinal tract infection. While their results indicated a significant reduction in infection incidence for infants whose mothers were in the intervention group, since breastfeeding was not randomized, causality could not reasonably be determined. Since breastfeeding can't ethnically be randomized, a secondary analysis using statistical techniques to assess causality was required.

# Question 2: Specify the longitudinal causal model $\mathcal{M^{F}}$ for individual level data (with endogenous nodes and time ordering corresponding to the observed data as specified in Section 3). What do you think about the temporal ordering assumptions? Any concerns? \textit{Bonus:} How might you modify this causal model to more accurately describe knowledge about the true data generating process?
The longitudinal causal model $\mathcal{M^{F}}$ is:
\begin{align*}
W &= \text{baseline covariates} \\
C_t, t = 1...K &= \text{Whether the subject was censored before the }t\text{th timepoint (including the final timepoint, }K\text{, which would indicate censoring at the time the outcome was measured.)} \\
L_t, t = 1...K-1 &= \text{Whether the infant had any gastrointestinal infections between timepoints} t\text{ - 1 and }t\text{. Any subject already censored during or prior to any given timepoint received an }L_t\text{ value of zero.} \\
A_t, t = 1...K-1 &= \text{Breastfeeding status at timepoint } t. \\
Y &= \text{the outcome: the total number of infections accrued up until and including visit }K. \text{Any subject censored during or prior to time }K\text{ received a }Y\text{ value of zero.} \\
\end{align*}

# Question 3: Specify the counterfactual outcomes of interest. Hint: First define the interventions of interest. Then define the counterfactual outcome under these interventions (the counterfactual outcome is a random variable). How are these counterfactual outcomes generated using an intervention on the causal model?
<SABRINA ANSWER HERE>

# Question 4: Specify the target causal parameter.
<SABRINA ANSWER HERE>

# Question 5: What are the observed data? What is the assumed link between the observed data and the structural causal model $\mathcal{M^{F}}$? Factorize the observed data distribution $P_0(O)$ according to the time-ordering.
<SABRINA ANSWER HERE>

# Question 6: What are the needed identifiability assumptions? Do they seem reasonable here? Any particular concerns?
<SABRINA ANSWER HERE>
-->

# Question 7: Under the assumption of sequential randomization and positivity, write out the (counterfactual or "post intervention") distribution $Q^{\bar{a}}$ a of the counterfactual non-intervention variables ($W$; $\bar{L}^{\bar{a}}_5$, $Y^{\bar{a}}$) as a function of the observed data distribution $P_0$.
<SABRINA ANSWER HERE>


# Question 8: Specify the statistical estimand using the traditional G-computation formula.
<!--(Fine to assume $W$ is discrete to keep the discrete notation we have been using in class, and write this in the form we have been using in class.)-->
<SABRINA ANSWER HERE>


# Question 9: Briefly review implementation of "traditional" longitudinal parametric G-Computation for this estimand. What are some possible pros/cons to this approach?
"Traditional" longitudinal parametric G-Computation requires:

* estimation of distribution of each time-varying covariate given the past, and
* evaluation through simulation.

\vspace{18pt} 

\begin{columns}
\begin{column}{0.48\textwidth}
\underline{Pros:}
\begin{itemize}
\item Fairly easy to set up and run
\item Efficient, if the model is correct
\end{itemize}
\end{column}
\begin{column}{0.48\textwidth}
\underline{Cons:}
\begin{itemize}
\item Susceptible to bias if model not correctly specified
\item Requires estimating lots of conditional densities
\end{itemize}
\end{column}
\end{columns}

<!--
# Question 10: What is the sequential representation of the statistical estimand? 
By sequentially breaking up the expectations into nested conditional expectations, the marginal expectation of the outcome assuming no censoring can be represented like this:

\begin{align*}
\Psi_{\bar{a}} &= E(Y_{\bar{a}}) \\
&= E\{E(Y|C_K = 0, \bar{A}_{K-1} = \bar{a}_{K-1}, \bar{L}_{K-1}, W)\} \\
&= E[E\{E(Y|C_K = 0, \bar{A}_{K-1} = \bar{a}_{K-1}, \bar{L}_{K-1}, W)|C_K = 0, \bar{A}_{K-2} = \bar{a}_{K-2}, \bar{L}_{K-2}, W\}] \\
\end{align*}

# Question 11: Give an overview of implementation of the sequential G computation estimator. What are some advantages over the traditional parametric G comp estimator?
To implement the sequential G-comp estimator, you fit a model for each level of conditioning, beginning with the innermost expectation (i.e. first fit $Q_K$ and then the rest of the $Q_t$s). Then predictions are obtained for each individual moving backward in time, eventually taking a mean of $Q_1$ over all observations, conditional only on the baseline covariates. That gives the target causal parameter.
  
This method provides a few advantages over the traditional parametric G-comp estimator described in Question 9, namely:

* No longer have to estimate a series of conditional densities
* Many fewer dimensions (don't need to estimate all the conditional densities in the same way)

# Question 12: Give an overview of implementation of the sequential TMLE.
To implement sequential TMLE, we go through the following steps:

1. Estimate $E_0(Y|A,W) \equiv \bar{Q}_0(A,W)$, for example using SuperLearner.
2. Generate predicted values for Y for each individual, given that individual's $A_i, W_i$.
3. Estimate the treatment mechanism, again using SuperLearner or similar ($g_0(A|W)$).
4. Use this estimate to create a new "clever covariate" ($H_n(A,W)$) for each individual.
5. Update the initial estimate of $E_0(Y|A,W)$ using that clever covariate, by running a logistic regression of $Y_i$ on $H_n(A_i,W_i)$ using log\textit{it}$(\bar{Q}^0_n(A_i,W_i))$ as an offset, and obtaining an MLE estimate of the coefficient $\epsilon$ on each clever covariate.
6. Calculate the predicted values for each individual under each treatment regimen using the updated estimate.
7. Update $\Psi(P_0)$ as the empirical mean of the predicted values of $Y$ based on the updated fit, for each treatment regimen of interest.
-->